package spark.simples

/**
  * 关于关系型运算的Join连接的数据倾斜状况。
  *
  * 数据倾斜原因如下：
  * 1）业务数据本身的特性
  * 2）Key分布不均匀
  * 3）建表时考虑不周
  * 4）某些SQL语句本身就有数据倾斜
  *
  * 数据倾斜表现如下：
  * 任务进度长时间维持，查看任务监控页面，由于其处理的数据量与其他任务差异过大，会发现只有少量（1个或几个）任务未完成。
  *
  * 应用场景：
  * 在大数据分析平台中，经常遇到数据倾斜问题，可以参照相应的思路处理数据倾斜。
  * SQL on Hadoop系统中也需要处理数据倾斜问题。
  */
object SkewJoin {

  def main(args: Array[String]): Unit = {
    /**
      * 输入：表A（数据倾斜），表B
      * 输出：表C（A，B连接后的表）
      *
      * 设计思路：
      *  假设表A和表B连接，表A数据倾斜，只有一个Key倾斜。首先对A进行采样，统计出最倾斜的Key。
      *  将A表分割为A1只有倾斜Key，A2不包含倾斜Key，然后分别与B连接。
      */

  }
}
